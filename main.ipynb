{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RedrugAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook demonstrates **RedrugAI**, a drug repurposing recommendation system built on Google BigQuery and BigQuery AI. The system leverages machine learning embeddings and vector similarity search to identify potential therapeutic applications for existing drugs in new disease contexts.\n",
        "\n",
        "### Dataset\n",
        "- **Open Targets Platform**: A comprehensive biomedical database containing drug-disease associations, molecular targets, and mechanisms of action accessible through BigQuery's public datasets\n",
        "\n",
        "### Key BigQuery AI Features\n",
        " \n",
        "- **ML.GENERATE_EMBEDDING**: Leverages Gemini embedding models to create high-quality semantic vectors for diseases and drug mechanisms of action\n",
        "- **VECTOR_SEARCH**: Utilizes BigQuery's native vector similarity functions for similar diseases.\n",
        "- **bigframes.bigquery.create_vector_index()**: Creates optimized vector indices for efficient similarity search across disease embeddings (38,959 diseases)\n",
        "\n",
        "### Workflow Overview\n",
        "\n",
        "1. **Data Preparation**: Create embedding tables for diseases and drug mechanisms using BigQuery AI\n",
        "2. **Similarity Computation**: Build similarity matrices using vector search capabilities  \n",
        "3. **Recommendation Engine**: Score candidate drugs based on known therapeutic relationships\n",
        "4. **Evaluation**: Validate recommendations against known drug-disease associations\n",
        "\n",
        "This approach enables researchers to discover novel therapeutic opportunities by identifying drugs with similar mechanisms or targets that could be effective for related diseases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up\n",
        "### Biquery \n",
        "- Create Biquery project 'redrugai' and dataset 'redrugai_data'\n",
        "- Create remote vertex model for text embeddings\n",
        "   https://cloud.google.com/bigquery/docs/generate-text-embedding#console_1\n",
        "### Python\n",
        "version >= 3.12.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade bigframes\n",
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import bigframes.bigquery as bbq\n",
        "import bigframes.pandas as bpd\n",
        "region = \"US\"\n",
        "project_id = \"redrugai\"\n",
        "dataset_id = \"redrugai_data\"\n",
        "embedding_model_name = 'embedding005'\n",
        "source_project_id = \"bigquery-public-data\"\n",
        "source_dataset_id = \"open_targets_platform\"\n",
        "# Configure BigQuery client  \n",
        "bpd.options.bigquery.project = project_id\n",
        "bpd.options.bigquery.location = region\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Tables\n",
        "- Only need to run once\n",
        "- Purpose: Pre-build embedding tables and similarity matrices for efficient vector search on public datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding Table\n",
        "1. disease_embedding table\n",
        "    - Source Table: disease.\n",
        "    - Convert Column: name, synonyms, description  \n",
        "2. drug_mechanism_of_action_embedding table\n",
        "    - Target Table: drug_mechanism_of_action. \n",
        "    - Convert Column: 'MoA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Disease embeddings table created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create disease embeddings table\n",
        "source_table_name = \"disease\"\n",
        "embedding_table_name = \"disease_embedding\"\n",
        "\n",
        "# Create table with disease embeddings by concatenating name, synonyms, and description\n",
        "query_create_embeddings = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{embedding_table_name}` AS\n",
        "WITH source_table AS (\n",
        "  SELECT\n",
        "    d.id,\n",
        "    d.name,\n",
        "    d.synonyms,\n",
        "    CONCAT(\n",
        "      'Name: ', d.name,\n",
        "      IFNULL(CONCAT('. Synonyms: ', STRING_AGG(DISTINCT syn.element, ', ')), ''),\n",
        "      IFNULL(CONCAT('. Description: ', d.description), '')\n",
        "    ) AS content\n",
        "  FROM `{source_project_id}.{source_dataset_id}.{source_table_name}` AS d\n",
        "  LEFT JOIN UNNEST(ARRAY_CONCAT(\n",
        "    IFNULL(d.synonyms.hasExactSynonym.list, []),\n",
        "    IFNULL(d.synonyms.hasRelatedSynonym.list, []),\n",
        "    IFNULL(d.synonyms.hasNarrowSynonym.list, []),\n",
        "    IFNULL(d.synonyms.hasBroadSynonym.list, [])\n",
        "  )) AS syn\n",
        "  GROUP BY d.id, d.name, d.description, d.synonyms\n",
        ")\n",
        "SELECT\n",
        "  s.id,\n",
        "  s.name,\n",
        "  s.synonyms,\n",
        "  e.ml_generate_embedding_result AS embedding\n",
        "FROM\n",
        "  source_table s\n",
        "JOIN\n",
        "  ML.GENERATE_EMBEDDING(\n",
        "    MODEL `{project_id}.{dataset_id}.{embedding_model_name}`,\n",
        "    (SELECT id, content FROM source_table),\n",
        "    STRUCT(TRUE AS flatten_json_output)\n",
        "  ) e\n",
        "ON s.id = e.id\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the embeddings table\n",
        "bpd.read_gbq(query_create_embeddings)\n",
        "print(\"Disease embeddings table created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "redrugai.redrugai_data.disease_embedding\n",
            "Vector index created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create a vector index for efficient searching on the disease embeddings table\n",
        "# Note: BigQuery requires minimum 5000 rows for IVF index type\n",
        "# If table has fewer rows, use VECTOR_SEARCH function directly without index\n",
        "full_table_id = f\"{project_id}.{dataset_id}.{embedding_table_name}\"\n",
        "print(full_table_id)\n",
        "\n",
        "try:\n",
        "    bbq.create_vector_index(\n",
        "        table_id=full_table_id,\n",
        "        column_name='embedding',\n",
        "    )\n",
        "    print(\"Vector index created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Vector index creation failed - {str(e)}\")\n",
        "    print(\"This is expected for tables with < 5000 rows. VECTOR_SEARCH will work without index.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mechanism of action embeddings table created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create unique mechanism of action (MoA) embedding table\n",
        "source_table_name = \"drug_mechanism_of_action\"\n",
        "embedding_table_name = \"drug_moa_embedding\"\n",
        "\n",
        "# Build embeddings for unique MoA values\n",
        "query_create_moa_embeddings = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{embedding_table_name}` AS\n",
        "WITH unique_moa AS (\n",
        "  SELECT DISTINCT TRIM(mechanismOfAction) AS content\n",
        "  FROM `{source_project_id}.{source_dataset_id}.{source_table_name}`\n",
        "  WHERE mechanismOfAction IS NOT NULL \n",
        "    AND TRIM(mechanismOfAction) != ''\n",
        ")\n",
        "SELECT\n",
        "  e.content AS mechanismOfAction,\n",
        "  e.ml_generate_embedding_result AS embedding\n",
        "FROM ML.GENERATE_EMBEDDING(\n",
        "  MODEL `{project_id}.{dataset_id}.{embedding_model_name}`,\n",
        "  TABLE unique_moa\n",
        ") AS e\n",
        "ORDER BY mechanismOfAction\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the MoA embeddings table\n",
        "bpd.read_gbq(query_create_moa_embeddings)\n",
        "print(\"Mechanism of action embeddings table created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MoA Similarity Matrix\n",
        "Create a comprehensive similarity table for all mechanism of action (MoA) pairs using the drug_moa_embedding table. This matrix will be used for drug recommendation scoring by comparing the similarity between different mechanisms of action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mechanism of action pair similarity matrix table created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Build mechanism of action (MoA) pair similarity matrix table\n",
        "moa_embedding_table_name = \"drug_moa_embedding\"\n",
        "similarity_table_name = f\"{moa_embedding_table_name}_similarity\"\n",
        "\n",
        "# Create comprehensive MoA pair similarity matrix for drug recommendation scoring\n",
        "query_create_moa_similarity = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{similarity_table_name}` AS\n",
        "WITH moa_pairs AS (\n",
        "  SELECT \n",
        "    a.mechanismOfAction AS moa_a,\n",
        "    b.mechanismOfAction AS moa_b,\n",
        "    a.embedding AS embedding_a,\n",
        "    b.embedding AS embedding_b\n",
        "  FROM `{project_id}.{dataset_id}.{moa_embedding_table_name}` a\n",
        "  CROSS JOIN `{project_id}.{dataset_id}.{moa_embedding_table_name}` b\n",
        ")\n",
        "SELECT\n",
        "  moa_a,\n",
        "  moa_b,\n",
        "  1 - ML.DISTANCE(embedding_a, embedding_b, 'COSINE') AS cosine_similarity\n",
        "FROM moa_pairs\n",
        "ORDER BY cosine_similarity DESC\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the MoA similarity table\n",
        "bpd.read_gbq(query_create_moa_similarity)\n",
        "print(\"Mechanism of action pair similarity matrix table created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MoA Flat Table\n",
        "Create a flattened table that maps each drug to its mechanisms of action and target proteins. This table simplifies the complex many-to-many relationships in the original data by creating one row per drug-MoA-target combination, making it easier to analyze drug similarities based on their biological mechanisms.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drug MoA flat table created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create a flattened table that maps drugs to their mechanisms of action and targets\n",
        "flat_table_name = \"drug_moa_flat\"\n",
        "\n",
        "query_create_moa_flat = f\"\"\"\n",
        "CREATE OR REPLACE TABLE `{project_id}.{dataset_id}.{flat_table_name}` AS\n",
        "WITH\n",
        "-- A) Drugs with a join key that prefers the parent when present\n",
        "dm AS (\n",
        "  SELECT\n",
        "    id                         AS molecule_id,\n",
        "    name                       AS drug_name,\n",
        "    COALESCE(parentId, id)     AS join_id\n",
        "  FROM bigquery-public-data.open_targets_platform.drug_molecule\n",
        "),\n",
        "-- B) Flatten MoA → target pairs from the MoA table\n",
        "moa_flat AS (\n",
        "  SELECT\n",
        "    chembl.element AS moa_molecule_id,\n",
        "    COALESCE(NULLIF(TRIM(dmoa.mechanismOfAction), ''),\n",
        "             NULLIF(TRIM(dmoa.actionType), '')) AS moa,\n",
        "    CAST(tgt.element AS STRING) AS target_id\n",
        "  FROM bigquery-public-data.open_targets_platform.drug_mechanism_of_action AS dmoa\n",
        "  CROSS JOIN UNNEST(dmoa.chemblIds.list) AS chembl\n",
        "  LEFT JOIN UNNEST(dmoa.targets.list) AS tgt ON TRUE\n",
        "),\n",
        "-- C) Map MoA rows to the parent when available\n",
        "moa_parentaware AS (\n",
        "  SELECT\n",
        "    COALESCE(dm2.parentId, dm2.id, mf.moa_molecule_id) AS join_id,\n",
        "    mf.moa_molecule_id,\n",
        "    mf.moa,\n",
        "    mf.target_id\n",
        "  FROM moa_flat AS mf\n",
        "  LEFT JOIN bigquery-public-data.open_targets_platform.drug_molecule dm2\n",
        "    ON dm2.id = mf.moa_molecule_id\n",
        ")\n",
        "-- D) Final\n",
        "SELECT\n",
        "  dm.molecule_id,\n",
        "  dm.drug_name,\n",
        "  mpa.moa,\n",
        "  mpa.target_id\n",
        "FROM dm\n",
        "LEFT JOIN moa_parentaware mpa\n",
        "  USING (join_id)\n",
        "QUALIFY ROW_NUMBER() OVER (\n",
        "  PARTITION BY dm.molecule_id, mpa.moa, mpa.target_id\n",
        ") = 1\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the flattened MoA table\n",
        "bpd.read_gbq(query_create_moa_flat)\n",
        "print(\"Drug MoA flat table created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First layer\n",
        "1. Generate an embedding for the query disease name\n",
        "2. Search for diseases with similar embeddings in our pre-computed disease embedding table\n",
        "3. Filter results by cosine distance threshold to ensure semantic relevance\n",
        "4. Return a ranked list of similar diseases that could share therapeutic targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similar diseases to 'trypanosomiasis' (distance < 0.3):\n",
            "Found 3 similar diseases\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Query job 51360f51-6a14-4983-846b-512daa621316 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=redrugai&j=bq:US:51360f51-6a14-4983-846b-512daa621316&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              id                   disease_name  distance\n",
            "0    EFO_0008559       American trypanosomiasis  0.213539\n",
            "1    EFO_0005225  human african trypanosomiasis  0.224497\n",
            "2  MONDO_0001444                 Chagas disease  0.277343\n",
            "\n",
            "[3 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Configuration for vector search\n",
        "base_table_name = \"disease_embedding\"\n",
        "text_embedding_model_name = \"embedding005\"\n",
        "query_text = 'trypanosomiasis'\n",
        "distance_threshold = 0.3\n",
        "\n",
        "# Construct vector search query to find similar diseases\n",
        "vector_search_query = f\"\"\"\n",
        "WITH query_table AS (\n",
        "    SELECT *\n",
        "    FROM ML.GENERATE_EMBEDDING(\n",
        "        MODEL `{project_id}.{dataset_id}.{text_embedding_model_name}`,\n",
        "        (SELECT '{query_text}' AS content)\n",
        "    )\n",
        ")\n",
        "SELECT\n",
        "    base.id,\n",
        "    base.name AS disease_name,\n",
        "    distance\n",
        "FROM\n",
        "    VECTOR_SEARCH(\n",
        "        TABLE `{project_id}.{dataset_id}.{base_table_name}`,\n",
        "        'embedding',\n",
        "        (SELECT * FROM query_table),\n",
        "        'ml_generate_embedding_result',\n",
        "        top_k => 100,\n",
        "        distance_type => 'COSINE'\n",
        "    )\n",
        "WHERE distance < {distance_threshold}\n",
        "ORDER BY distance ASC\n",
        "\"\"\"\n",
        "\n",
        "# Execute the vector search query\n",
        "similar_disease_df = bpd.read_gbq(vector_search_query)\n",
        "\n",
        "# Exclude exact matches and filter results\n",
        "similar_disease_df = similar_disease_df[\n",
        "    similar_disease_df['disease_name'].str.lower() != query_text.lower()\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Similar diseases to '{query_text}' (distance < {distance_threshold}):\")\n",
        "print(f\"Found {len(similar_disease_df)} similar diseases\")\n",
        "print(similar_disease_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Second Layer\n",
        "1. Finding diseases similar to the query disease using vector embeddings\n",
        "2. Collecting known drugs for these similar diseases\n",
        "3. Computing drug similarity scores based on mechanism of action (MOA)\n",
        "4. Ranking and filtering drug candidates for the target disease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading datasets...\n",
            "Executing BigQuery operations...\n",
            "Loaded 27499 drugs, 253442 disease-drug relationships, and 2812329 MOA similarity pairs\n"
          ]
        }
      ],
      "source": [
        "# Load required datasets for drug recommendation\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Query to get disease-drug relationships with mechanism of action and targets\n",
        "query_disease_drugs = \"\"\"\n",
        "SELECT \n",
        "    kd.diseaseId,\n",
        "    d.name AS disease_name,\n",
        "    kd.drugId,\n",
        "    kd.mechanismOfAction AS moa,\n",
        "    kd.targetId AS target_id\n",
        "FROM\n",
        "    `bigquery-public-data.open_targets_platform.known_drug` kd\n",
        "INNER JOIN\n",
        "    `bigquery-public-data.open_targets_platform.disease` d\n",
        "ON\n",
        "    d.id = kd.diseaseId\n",
        "\"\"\"\n",
        "\n",
        "# Query to get comprehensive drug information with MOA details\n",
        "query_all_drugs = \"\"\"\n",
        "SELECT *\n",
        "FROM `redrugai.redrugai_data.drug_moa_flat`\n",
        "\"\"\"\n",
        "\n",
        "# Query to get pre-computed MOA similarity scores\n",
        "query_moa_pair_similarity = \"\"\"\n",
        "SELECT *\n",
        "FROM `redrugai.redrugai_data.drug_moa_embedding_similarity`\n",
        "\"\"\"\n",
        "\n",
        "# Execute queries and load data\n",
        "print(\"Executing BigQuery operations...\")\n",
        "all_drugs_df = bpd.read_gbq(query_all_drugs)\n",
        "disease_drugs_df = bpd.read_gbq(query_disease_drugs)\n",
        "moa_pair_sim_df = bpd.read_gbq(query_moa_pair_similarity)\n",
        "\n",
        "print(f\"Loaded {len(all_drugs_df)} drugs, {len(disease_drugs_df)} disease-drug relationships, and {len(moa_pair_sim_df)} MOA similarity pairs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from score import *\n",
        "\n",
        "# Execute the recommendation system for the queried disease\n",
        "result = recommend_for_disease_with_similars(\n",
        "    disease_name=query_text,\n",
        "    similar_disease_names=similar_disease_df['disease_name'].to_list(),\n",
        "    disease_drugs_df=disease_drugs_df,\n",
        "    all_drugs_df=all_drugs_df,\n",
        "    moa_pair_sim_df=moa_pair_sim_df,\n",
        "    top_overall=10,\n",
        "    top_similar=5,\n",
        "    similar_weight=0.5,\n",
        "    evaluation_mode=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Disease Analysis Results for: trypanosomiasis\n",
            "============================================================\n",
            "\n",
            "💊 Known Drugs (5 found):\n",
            "  1. CHEMBL265502\n",
            "  2. CHEMBL413376\n",
            "  3. CHEMBL52440\n",
            "  4. CHEMBL655\n",
            "  5. CHEMBL830\n",
            "\n",
            "🎯 Overall Recommendations (10 drugs):\n",
            "  1. EFLORNITHINE HYDROCHLORIDE (Score: 6.401)\n",
            "  2. DEXTROMETHORPHAN POLISTIREX (Score: 5.278)\n",
            "  3. DEXTROMETHORPHAN HYDROBROMIDE (Score: 5.278)\n",
            "  4. CARBETAPENTANE CITRATE (Score: 5.264)\n",
            "  5. CARBETAPENTANE (Score: 5.264)\n",
            "  6. DIAZEPAM (Score: 3.009)\n",
            "  7. MIDAZOLAM HYDROCHLORIDE (Score: 3.009)\n",
            "  8. QUAZEPAM (Score: 3.009)\n",
            "  9. CHLORDIAZEPOXIDE HYDROCHLORIDE (Score: 3.009)\n",
            "  10. METHYPRYLON (Score: 3.009)\n",
            "\n",
            "🔗 Similar Disease Recommendations (1 drugs):\n",
            "  1. ATORVASTATIN (Score: 0.604)\n"
          ]
        }
      ],
      "source": [
        "# Display recommendation results\n",
        "print(f\"\\n🔍 Disease Analysis Results for: {query_text}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n💊 Known Drugs ({len(result['known_drugs'])} found):\")\n",
        "if not result[\"known_drugs\"].empty:\n",
        "    for idx, row in result[\"known_drugs\"].iterrows():\n",
        "        print(f\"  {idx+1}. {row.get('drug_name', row['drugId'])}\")\n",
        "else:\n",
        "    print(\"  No known drugs found for this disease\")\n",
        "\n",
        "print(f\"\\n🎯 Overall Recommendations ({len(result['overall_recommendations'])} drugs):\")\n",
        "if not result[\"overall_recommendations\"].empty:\n",
        "    for idx, row in result[\"overall_recommendations\"].iterrows():\n",
        "        score = row['final_score']\n",
        "        drug_name = row.get('drug_name', row['drugId'])\n",
        "        print(f\"  {idx+1}. {drug_name} (Score: {score:.3f})\")\n",
        "else:\n",
        "    print(\"  No recommendations available\")\n",
        "\n",
        "print(f\"\\n🔗 Similar Disease Recommendations ({len(result['similar_recommendations'])} drugs):\")\n",
        "if not result[\"similar_recommendations\"].empty:\n",
        "    for idx, row in result[\"similar_recommendations\"].iterrows():\n",
        "        score = row['score_against_primary']\n",
        "        drug_name = row.get('drug_name', row['drugId'])\n",
        "        print(f\"  {idx+1}. {drug_name} (Score: {score:.3f})\")\n",
        "else:\n",
        "    print(\"  No similar disease recommendations available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Evaluation\n",
        "\n",
        "**Important Caveat**: This recommendation system is designed to find potential drugs which cannot be validated as useful in real life without extensive clinical testing. These metrics are simply to evaluate if our approach can generate results that overlap with existing known drugs - this is not a strict academic evaluation method. If we find overlap, it shows to some level that our method has potential for drug discovery.\n",
        "\n",
        "1. Randomly Sample 100 Disease from disease table\n",
        "2. Get the recommendation drugs from similar drugs\n",
        "3. Measure the overlay level with the following metrics:\n",
        "    - **Precision**: How many recommendation drugs are in answer group (already known drugs)\n",
        "    - **Recall**: How many answer group drugs are in recommendation group\n",
        "    - **F1 Score**: Harmonic mean of precision and recall\n",
        "    - **Overlap Count**: Total number of overlapping drugs between recommendations and known drugs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from evaluation import run_disease_evaluation, get_random_diseases_sample\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling 100 random diseases...\n",
            "Sampled 100 diseases:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Query job a0660893-1c7b-4dea-82b6-d3dda4c326e1 is DONE. 0 Bytes processed. <a target=\"_blank\" href=\"https://console.cloud.google.com/bigquery?project=redrugai&j=bq:US:a0660893-1c7b-4dea-82b6-d3dda4c326e1&page=queryresults\">Open Job</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    disease_name  known_drug_count\n",
            "0              Uterine leiomyoma                 2\n",
            "1  idiopathic pulmonary fibrosis                62\n",
            "2       fetal growth restriction                 6\n",
            "3                    Cholangitis                 1\n",
            "4               Immunodeficiency                 3\n",
            "\n",
            "[5 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Sample 100 random diseases with at least 1 known drug\n",
        "print(\"Sampling 100 random diseases...\")\n",
        "random_diseases_df = get_random_diseases_sample(\n",
        "    n_samples=100,\n",
        "    project_id=project_id,\n",
        "    source_project_id=source_project_id,\n",
        "    source_dataset_id=source_dataset_id,\n",
        "    min_known_drugs=1\n",
        ")\n",
        "\n",
        "print(f\"Sampled {len(random_diseases_df)} diseases:\")\n",
        "print(random_diseases_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running evaluation experiments...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating diseases:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating disease 1/100: Uterine leiomyoma\n",
            "  Success: 2 known drugs, 10 overall recs, 5 similar recs\n",
            "  Overall: P=0.000, R=0.000, F1=0.000\n",
            "  Similar: P=0.200, R=0.500, F1=0.286\n",
            "  Combined: P=0.067, R=0.500, F1=0.118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating diseases:   1%|          | 1/100 [01:00<1:40:05, 60.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating disease 2/100: idiopathic pulmonary fibrosis\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation experiments for all sampled diseases\n",
        "print(\"Running evaluation experiments...\")\n",
        "\n",
        "# Convert random_diseases_df to pandas for iteration\n",
        "diseases_list = random_diseases_df.to_pandas()['disease_name'].tolist()\n",
        "\n",
        "# Store results\n",
        "evaluation_results = []\n",
        "\n",
        "# Run experiments with progress bar\n",
        "for i, disease_name in enumerate(tqdm(diseases_list, desc=\"Evaluating diseases\")):\n",
        "    print(f\"\\nEvaluating disease {i+1}/100: {disease_name}\")\n",
        "    \n",
        "    # Run single disease evaluation\n",
        "    result = run_disease_evaluation(\n",
        "        disease_name=disease_name,\n",
        "        disease_drugs_df=disease_drugs_df,\n",
        "        all_drugs_df=all_drugs_df,\n",
        "        moa_pair_sim_df=moa_pair_sim_df,\n",
        "        disease_embedding_df=None,  # Will be handled inside the function\n",
        "        project_id=project_id,\n",
        "        dataset_id=dataset_id,\n",
        "        embedding_model_name=text_embedding_model_name,\n",
        "        distance_threshold=distance_threshold,\n",
        "        top_overall=10,\n",
        "        top_similar=5,\n",
        "        similar_weight=0.5\n",
        "    )\n",
        "    \n",
        "    evaluation_results.append(result)\n",
        "    \n",
        "    # Print progress summary\n",
        "    if result['success']:\n",
        "        metrics = result['metrics']\n",
        "        print(f\"  Success: {result['known_drugs_count']} known drugs, \"\n",
        "              f\"{result['overall_recommendations_count']} overall recs, \"\n",
        "              f\"{result['similar_recommendations_count']} similar recs\")\n",
        "        if 'overall_precision' in metrics:\n",
        "            print(f\"  Overall: P={metrics['overall_precision']:.3f}, \"\n",
        "                  f\"R={metrics['overall_recall']:.3f}, \"\n",
        "                  f\"F1={metrics['overall_f1_score']:.3f}\")\n",
        "        if 'similar_precision' in metrics:\n",
        "            print(f\"  Similar: P={metrics['similar_precision']:.3f}, \"\n",
        "                  f\"R={metrics['similar_recall']:.3f}, \"\n",
        "                  f\"F1={metrics['similar_f1_score']:.3f}\")\n",
        "        if 'combined_precision' in metrics:\n",
        "            print(f\"  Combined: P={metrics['combined_precision']:.3f}, \"\n",
        "                  f\"R={metrics['combined_recall']:.3f}, \"\n",
        "                  f\"F1={metrics['combined_f1_score']:.3f}\")\n",
        "    else:\n",
        "        print(f\"  Failed: {result['error']}\")\n",
        "    \n",
        "    # Small delay to avoid overwhelming BigQuery\n",
        "    time.sleep(0.5)\n",
        "\n",
        "print(f\"\\nCompleted evaluation of {len(evaluation_results)} diseases\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregating evaluation results...\n",
            "Created results DataFrame with 5 rows and 27 columns\n",
            "\n",
            "DataFrame columns:\n",
            "['disease_name', 'success', 'error', 'similar_diseases_count', 'train_drugs_count', 'test_drugs_count', 'known_drugs_count', 'overall_recommendations_count', 'similar_recommendations_count', 'overall_known_count', 'overall_recs_count', 'overall_overlap_count', 'overall_precision', 'overall_recall', 'overall_f1_score', 'similar_known_count', 'similar_recs_count', 'similar_overlap_count', 'similar_precision', 'similar_recall', 'similar_f1_score', 'combined_known_count', 'combined_recs_count', 'combined_overlap_count', 'combined_precision', 'combined_recall', 'combined_f1_score']\n",
            "\n",
            "Evaluation Summary:\n",
            "Successful evaluations: 5/5\n",
            "Failed evaluations: 0/5\n",
            "\n",
            "First 5 results:\n",
            "                            disease_name  success  train_drugs_count  \\\n",
            "0                      esophageal cancer     True                  0   \n",
            "1     proliferative diabetic retinopathy     True                  0   \n",
            "2                cutaneous Leishmaniasis     True                  0   \n",
            "3                   acute kidney failure     True                  0   \n",
            "4  chronic obstructive pulmonary disease     True                  0   \n",
            "\n",
            "   test_drugs_count  overall_recommendations_count  overall_precision  \\\n",
            "0                 0                             10                0.6   \n",
            "1                 0                             10                0.0   \n",
            "2                 0                             10                0.2   \n",
            "3                 0                             10                0.1   \n",
            "4                 0                             10                0.2   \n",
            "\n",
            "   overall_recall  overall_f1_score  \n",
            "0        0.065217          0.117647  \n",
            "1        0.000000          0.000000  \n",
            "2        0.400000          0.266667  \n",
            "3        0.500000          0.166667  \n",
            "4        0.012121          0.022857  \n"
          ]
        }
      ],
      "source": [
        "# Aggregate results as DataFrame\n",
        "print(\"Aggregating evaluation results...\")\n",
        "\n",
        "# Flatten the results into a DataFrame\n",
        "results_data = []\n",
        "for result in evaluation_results:\n",
        "    # Base information\n",
        "    row = {\n",
        "        'disease_name': result['disease_name'],\n",
        "        'success': result['success'],\n",
        "        'error': result.get('error', None),\n",
        "        'similar_diseases_count': result.get('similar_diseases_count', 0),\n",
        "        'train_drugs_count': result.get('train_drugs_count', 0),\n",
        "        'test_drugs_count': result.get('test_drugs_count', 0),\n",
        "        'known_drugs_count': result.get('known_drugs_count', 0),\n",
        "        'overall_recommendations_count': result.get('overall_recommendations_count', 0),\n",
        "        'similar_recommendations_count': result.get('similar_recommendations_count', 0)\n",
        "    }\n",
        "    \n",
        "    # Add metrics if available\n",
        "    if 'metrics' in result and result['metrics']:\n",
        "        row.update(result['metrics'])\n",
        "    \n",
        "    results_data.append(row)\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results_data)\n",
        "\n",
        "print(f\"Created results DataFrame with {len(results_df)} rows and {len(results_df.columns)} columns\")\n",
        "print(\"\\nDataFrame columns:\")\n",
        "print(results_df.columns.tolist())\n",
        "\n",
        "# Display summary statistics\n",
        "print(f\"\\nEvaluation Summary:\")\n",
        "print(f\"Successful evaluations: {results_df['success'].sum()}/{len(results_df)}\")\n",
        "print(f\"Failed evaluations: {(~results_df['success']).sum()}/{len(results_df)}\")\n",
        "\n",
        "# Display sample results\n",
        "print(f\"\\nFirst 5 results:\")\n",
        "display_cols = ['disease_name', 'success', 'train_drugs_count', 'test_drugs_count', 'overall_recommendations_count', \n",
        "                'overall_precision', 'overall_recall', 'overall_f1_score']\n",
        "available_cols = [col for col in display_cols if col in results_df.columns]\n",
        "print(results_df[available_cols].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== EVALUATION ANALYSIS ===\n",
            "\n",
            "Analyzing 5 successful evaluations:\n",
            "\n",
            "Performance Metrics Summary:\n",
            "  overall_precision: 0.2200 ± 0.2280\n",
            "  overall_recall: 0.1955 ± 0.2363\n",
            "  overall_f1_score: 0.1148 ± 0.1089\n",
            "  similar_precision: 0.1600 ± 0.3578\n",
            "  similar_recall: 0.0087 ± 0.0194\n",
            "  similar_f1_score: 0.0165 ± 0.0369\n",
            "  combined_precision: 0.2174 ± 0.2385\n",
            "  combined_recall: 0.1998 ± 0.2335\n",
            "  combined_f1_score: 0.1134 ± 0.1075\n",
            "\n",
            "Count Statistics:\n",
            "  Average known drugs per disease: 55.60\n",
            "  Average recommendations per disease: 10.00\n",
            "  Average similar diseases found: 3.20\n",
            "\n",
            "Overlap Analysis:\n",
            "  Diseases with at least 1 overlap: 4/5\n",
            "  Average overlap count: 2.20\n",
            "  Max overlap count: 6\n",
            "\n",
            "Results saved to 'evaluation_results.csv'\n",
            "\n",
            "=== EVALUATION COMPLETE ===\n",
            "\n",
            "Final Summary:\n",
            "Total diseases evaluated: 5\n",
            "Successful evaluations: 5\n",
            "Failed evaluations: 0\n",
            "Average Overall Precision: 0.2200\n",
            "Average Overall Recall: 0.1955\n",
            "Average Overall F1-Score: 0.1148\n",
            "Average Similar Precision: 0.1600\n",
            "Average Similar Recall: 0.0087\n",
            "Average Similar F1-Score: 0.0165\n",
            "Average Combined Precision: 0.2174\n",
            "Average Combined Recall: 0.1998\n",
            "Average Combined F1-Score: 0.1134\n"
          ]
        }
      ],
      "source": [
        "# Analyze evaluation results\n",
        "print(\"=== EVALUATION ANALYSIS ===\")\n",
        "\n",
        "# Filter successful evaluations only\n",
        "successful_results = results_df[results_df['success'] == True]\n",
        "\n",
        "if len(successful_results) > 0:\n",
        "    print(f\"\\nAnalyzing {len(successful_results)} successful evaluations:\")\n",
        "    \n",
        "    # Overall performance metrics\n",
        "    numeric_cols = successful_results.select_dtypes(include=[float, int]).columns\n",
        "    metric_cols = [col for col in numeric_cols if any(keyword in col.lower() \n",
        "                   for keyword in ['precision', 'recall', 'f1_score'])]\n",
        "    \n",
        "    if metric_cols:\n",
        "        print(f\"\\nPerformance Metrics Summary:\")\n",
        "        for col in metric_cols:\n",
        "            if col in successful_results.columns:\n",
        "                mean_val = successful_results[col].mean()\n",
        "                std_val = successful_results[col].std()\n",
        "                print(f\"  {col}: {mean_val:.4f} ± {std_val:.4f}\")\n",
        "    \n",
        "    # Count-based statistics\n",
        "    print(f\"\\nCount Statistics:\")\n",
        "    print(f\"  Average known drugs per disease: {successful_results['known_drugs_count'].mean():.2f}\")\n",
        "    print(f\"  Average recommendations per disease: {successful_results['overall_recommendations_count'].mean():.2f}\")\n",
        "    print(f\"  Average similar diseases found: {successful_results['similar_diseases_count'].mean():.2f}\")\n",
        "    \n",
        "    # Overlap analysis\n",
        "    if 'overall_overlap_count' in successful_results.columns:\n",
        "        overlap_stats = successful_results['overall_overlap_count']\n",
        "        print(f\"\\nOverlap Analysis:\")\n",
        "        print(f\"  Diseases with at least 1 overlap: {(overlap_stats > 0).sum()}/{len(successful_results)}\")\n",
        "        print(f\"  Average overlap count: {overlap_stats.mean():.2f}\")\n",
        "        print(f\"  Max overlap count: {overlap_stats.max()}\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv('evaluation_results.csv', index=False)\n",
        "    print(f\"\\nResults saved to 'evaluation_results.csv'\")\n",
        "    \n",
        "else:\n",
        "    print(\"No successful evaluations to analyze.\")\n",
        "\n",
        "print(\"\\n=== EVALUATION COMPLETE ===\")\n",
        "\n",
        "# Display final summary\n",
        "print(f\"\\nFinal Summary:\")\n",
        "print(f\"Total diseases evaluated: {len(results_df)}\")\n",
        "print(f\"Successful evaluations: {results_df['success'].sum()}\")\n",
        "print(f\"Failed evaluations: {(~results_df['success']).sum()}\")\n",
        "\n",
        "if len(successful_results) > 0 and 'overall_precision' in successful_results.columns:\n",
        "    # Overall metrics\n",
        "    avg_precision = successful_results['overall_precision'].mean()\n",
        "    avg_recall = successful_results['overall_recall'].mean()\n",
        "    avg_f1 = successful_results['overall_f1_score'].mean()\n",
        "    print(f\"Average Overall Precision: {avg_precision:.4f}\")\n",
        "    print(f\"Average Overall Recall: {avg_recall:.4f}\")\n",
        "    print(f\"Average Overall F1-Score: {avg_f1:.4f}\")\n",
        "    \n",
        "    # Similar disease metrics\n",
        "    if 'similar_precision' in successful_results.columns:\n",
        "        sim_precision = successful_results['similar_precision'].mean()\n",
        "        sim_recall = successful_results['similar_recall'].mean()\n",
        "        sim_f1 = successful_results['similar_f1_score'].mean()\n",
        "        print(f\"Average Similar Precision: {sim_precision:.4f}\")\n",
        "        print(f\"Average Similar Recall: {sim_recall:.4f}\")\n",
        "        print(f\"Average Similar F1-Score: {sim_f1:.4f}\")\n",
        "    \n",
        "    # Combined metrics  \n",
        "    if 'combined_precision' in successful_results.columns:\n",
        "        comb_precision = successful_results['combined_precision'].mean()\n",
        "        comb_recall = successful_results['combined_recall'].mean()\n",
        "        comb_f1 = successful_results['combined_f1_score'].mean()\n",
        "        print(f\"Average Combined Precision: {comb_precision:.4f}\")\n",
        "        print(f\"Average Combined Recall: {comb_recall:.4f}\")\n",
        "        print(f\"Average Combined F1-Score: {comb_f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
